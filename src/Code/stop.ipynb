{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd018c6ec67850db9699abd5399e8d8d3fa2a87f456187f67936ff0e21f5254793e",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "numpy==1.20.2\nscikit-learn==0.23.2\npandas==1.1.3\nnltk==3.5\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import csv\n",
    "import re\n",
    "from string import punctuation\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import logging\n",
    "from numpy import random\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "import pkg_resources\n",
    "import types\n",
    "def get_imports():\n",
    "    for name, val in globals().items():\n",
    "        if isinstance(val, types.ModuleType):\n",
    "            # Split ensures you get root package, \n",
    "            # not just imported function\n",
    "            name = val.__name__.split(\".\")[0]\n",
    "\n",
    "        elif isinstance(val, type):\n",
    "            name = val.__module__.split(\".\")[0]\n",
    "\n",
    "        # Some packages are weird and have different\n",
    "        # imported names vs. system names\n",
    "        if name == \"PIL\":\n",
    "            name = \"Pillow\"\n",
    "        elif name == \"sklearn\":\n",
    "            name = \"scikit-learn\"\n",
    "\n",
    "        yield name\n",
    "imports = list(set(get_imports()))\n",
    "\n",
    "requirements = []\n",
    "for m in pkg_resources.working_set:\n",
    "    if m.project_name in imports and m.project_name!=\"pip\":\n",
    "        requirements.append((m.project_name, m.version))\n",
    "\n",
    "for r in requirements:\n",
    "    print(\"{}=={}\".format(*r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_direct = '../Data/review_polarity/txt_sentoken/neg/'\n",
    "pos_direct = '../Data/review_polarity/txt_sentoken/pos/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading through the direc\n",
    "def get_filename(path):\n",
    "    filenames = []\n",
    "    files = [i.path for i in os.scandir(path) if i.is_file()]\n",
    "\n",
    "    for filename in files:\n",
    "        filename = os.path.basename(filename)\n",
    "        filenames.append(filename)\n",
    "    return filenames\n",
    "\n",
    "neg_files = get_filename(neg_direct)\n",
    "pos_files = get_filename(pos_direct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('neg.csv', 'w',  encoding = 'utf8', newline = '') as csv_file:\n",
    "    for _file in neg_files:\n",
    "\n",
    "        file_name = _file\n",
    "        with open(neg_direct +'/'+ _file,'r') as f:\n",
    "            text = f.read()\n",
    "\n",
    "            writer = csv.writer(csv_file)\n",
    "            writer.writerow([file_name, text])\n",
    "with open('pos.csv', 'w',  encoding = 'utf8', newline = '') as csv_file:\n",
    "    for _file in pos_files:\n",
    "\n",
    "        file_name = _file\n",
    "        with open(pos_direct +'/'+ _file,'r') as f:\n",
    "            text = f.read()\n",
    "\n",
    "            writer = csv.writer(csv_file)\n",
    "            writer.writerow([file_name, text])\n",
    "df_neg = pd.read_csv('neg.csv', header = None)\n",
    "df_pos = pd.read_csv('pos.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_neg['Label'] = ['Negative']*len(df_neg)\n",
    "df_pos['Label'] = ['Positive']*len(df_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                ID                                               Text  \\\n",
       "0  cv839_21467.txt  assume nothing . \\nthe phrase is perhaps one o...   \n",
       "1  cv034_29647.txt  plot : derek zoolander is a male model . \\nhe ...   \n",
       "2  cv908_16009.txt  i actually am a fan of the original 1961 or so...   \n",
       "3  cv748_12786.txt  a movie that's been as highly built up as the ...   \n",
       "4  cv253_10077.txt   \" good will hunting \" is two movies in one : ...   \n",
       "\n",
       "      Label  \n",
       "0  Positive  \n",
       "1  Positive  \n",
       "2  Positive  \n",
       "3  Positive  \n",
       "4  Positive  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>Text</th>\n      <th>Label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>cv839_21467.txt</td>\n      <td>assume nothing . \\nthe phrase is perhaps one o...</td>\n      <td>Positive</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>cv034_29647.txt</td>\n      <td>plot : derek zoolander is a male model . \\nhe ...</td>\n      <td>Positive</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>cv908_16009.txt</td>\n      <td>i actually am a fan of the original 1961 or so...</td>\n      <td>Positive</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>cv748_12786.txt</td>\n      <td>a movie that's been as highly built up as the ...</td>\n      <td>Positive</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>cv253_10077.txt</td>\n      <td>\" good will hunting \" is two movies in one : ...</td>\n      <td>Positive</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "df_pos = df_pos.rename(columns = {0:'ID', 1:'Text'})\n",
    "df_neg = df_neg.rename(columns = {0:'ID', 1:'Text'})\n",
    "df_pos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                ID                                               Text  \\\n",
       "0  cv676_22202.txt  bad . bad . \\nbad . \\nthat one word seems to p...   \n",
       "1  cv839_22807.txt  isn't it the ultimate sign of a movie's cinema...   \n",
       "2   cv155_7845.txt   \" gordy \" is not a movie , it is a 90-minute-...   \n",
       "3  cv465_23401.txt  disconnect the phone line . \\ndon't accept the...   \n",
       "4  cv398_17047.txt  when robert forster found himself famous again...   \n",
       "\n",
       "      Label  \n",
       "0  Negative  \n",
       "1  Negative  \n",
       "2  Negative  \n",
       "3  Negative  \n",
       "4  Negative  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>Text</th>\n      <th>Label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>cv676_22202.txt</td>\n      <td>bad . bad . \\nbad . \\nthat one word seems to p...</td>\n      <td>Negative</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>cv839_22807.txt</td>\n      <td>isn't it the ultimate sign of a movie's cinema...</td>\n      <td>Negative</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>cv155_7845.txt</td>\n      <td>\" gordy \" is not a movie , it is a 90-minute-...</td>\n      <td>Negative</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>cv465_23401.txt</td>\n      <td>disconnect the phone line . \\ndon't accept the...</td>\n      <td>Negative</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>cv398_17047.txt</td>\n      <td>when robert forster found himself famous again...</td>\n      <td>Negative</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "sources = [df_neg, df_pos]\n",
    "all_data = pd.concat(sources)\n",
    "all_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                ID                                               Text  \\\n",
       "0  cv762_15604.txt  if you're going to make a two-hour hollywood i...   \n",
       "1   cv817_3675.txt  we're back in blade runner territory with this...   \n",
       "2  cv445_26683.txt  phaedra cinema , the distributor of such never...   \n",
       "3  cv299_16214.txt  expectation rating : a bit worse than expected...   \n",
       "4  cv558_29507.txt   \" the endurance : shackleton's legendary anta...   \n",
       "\n",
       "      Label  \n",
       "0  Negative  \n",
       "1  Negative  \n",
       "2  Negative  \n",
       "3  Positive  \n",
       "4  Positive  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>Text</th>\n      <th>Label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>cv762_15604.txt</td>\n      <td>if you're going to make a two-hour hollywood i...</td>\n      <td>Negative</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>cv817_3675.txt</td>\n      <td>we're back in blade runner territory with this...</td>\n      <td>Negative</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>cv445_26683.txt</td>\n      <td>phaedra cinema , the distributor of such never...</td>\n      <td>Negative</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>cv299_16214.txt</td>\n      <td>expectation rating : a bit worse than expected...</td>\n      <td>Positive</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>cv558_29507.txt</td>\n      <td>\" the endurance : shackleton's legendary anta...</td>\n      <td>Positive</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "all_data = all_data.sample(frac=1).reset_index(drop=True)\n",
    "all_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                ID                                               Text  \\\n",
       "0  cv762_15604.txt  if you're going to make a two-hour hollywood i...   \n",
       "1   cv817_3675.txt  we're back in blade runner territory with this...   \n",
       "2  cv445_26683.txt  phaedra cinema , the distributor of such never...   \n",
       "3  cv299_16214.txt  expectation rating : a bit worse than expected...   \n",
       "4  cv558_29507.txt   \" the endurance : shackleton's legendary anta...   \n",
       "\n",
       "      Label                                         Clean_text  \n",
       "0  Negative  f u re gng  ke  w hur hllw n jke   wh bher rel...  \n",
       "1  Negative  we re bck n ble runner errr wh h ne   cncepul ...  \n",
       "2  Negative  pher cne   he rbur f uch never her f clc    f ...  \n",
       "3  Positive  expecn rng    b wre hn expece   nl becue  fun ...  \n",
       "4  Positive     he enurnce   hcklen  legenr nrcc expen    n...  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>Text</th>\n      <th>Label</th>\n      <th>Clean_text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>cv762_15604.txt</td>\n      <td>if you're going to make a two-hour hollywood i...</td>\n      <td>Negative</td>\n      <td>f u re gng  ke  w hur hllw n jke   wh bher rel...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>cv817_3675.txt</td>\n      <td>we're back in blade runner territory with this...</td>\n      <td>Negative</td>\n      <td>we re bck n ble runner errr wh h ne   cncepul ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>cv445_26683.txt</td>\n      <td>phaedra cinema , the distributor of such never...</td>\n      <td>Negative</td>\n      <td>pher cne   he rbur f uch never her f clc    f ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>cv299_16214.txt</td>\n      <td>expectation rating : a bit worse than expected...</td>\n      <td>Positive</td>\n      <td>expecn rng    b wre hn expece   nl becue  fun ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>cv558_29507.txt</td>\n      <td>\" the endurance : shackleton's legendary anta...</td>\n      <td>Positive</td>\n      <td>he enurnce   hcklen  legenr nrcc expen    n...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "def text_cleaning(text):\n",
    "    # Clean the text data\n",
    "\n",
    "    text = re.sub(r\"[^A-Za-z0-9]\", \" \", text)\n",
    "    text = re.sub(r'\\b\\d+(?:\\.\\d+)?\\s+', '', text) # remove numbers\n",
    "    text = text.lower()  # set in lowercase \n",
    "    \n",
    "    text = ''.join([c for c in text if c not in STOPWORDS])\n",
    "        \n",
    "    # Remove punctuation from text\n",
    "    text = ''.join([c for c in text if c not in punctuation])\n",
    "        \n",
    "    # Return a list of words\n",
    "    return(text)\n",
    "all_data['Clean_text'] = all_data['Text'].apply(text_cleaning)\n",
    "all_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature Extraction\n",
    "cv = CountVectorizer()\n",
    "tfidf_vect = TfidfVectorizer()\n",
    "X = all_data['Clean_text']\n",
    "y = all_data['Label']\n",
    "cv.fit(X)\n",
    "tfidf_vect.fit(X)\n",
    "X_cv = cv.transform(X)\n",
    "X_tfidf = tfidf_vect.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_cv, X_test_cv, y_train, y_test = train_test_split(X_cv, y, test_size=0.3, random_state=42)\n",
    "X_train_tf, X_test_tf, y_train, y_test = train_test_split(X_tfidf, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = MultinomialNB()\n",
    "base_model.fit(X_train_cv, y_train)\n",
    "cv_predictions = base_model.predict(X_test_cv)\n",
    "base_model_tf = MultinomialNB()\n",
    "base_model_tf.fit(X_train_tf, y_train)\n",
    "tfidf_predictions = base_model_tf.predict(X_test_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model Accuracy using Count Vectorizer is 0.8283333333333334: Model accuracy using TFIDF is 0.675\n"
     ]
    }
   ],
   "source": [
    "cv_acc = accuracy_score(cv_predictions, y_test)\n",
    "tfidf_acc = accuracy_score(tfidf_predictions, y_test)\n",
    "print(\"Model Accuracy using Count Vectorizer is {}\".format(cv_acc) + \\\n",
    "      \": \" +\"Model accuracy using TFIDF is {}\".format(tfidf_acc) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              precision    recall  f1-score   support\n\n    Negative       0.86      0.79      0.83       308\n    Positive       0.80      0.87      0.83       292\n\n    accuracy                           0.83       600\n   macro avg       0.83      0.83      0.83       600\nweighted avg       0.83      0.83      0.83       600\n\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(cv_predictions, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model1 = SVC()\n",
    "base_model1.fit(X_train_cv, y_train)\n",
    "cv_predictions1 = base_model1.predict(X_test_cv)\n",
    "base_model1_tf = SVC()\n",
    "base_model1_tf.fit(X_train_tf, y_train)\n",
    "tfidf_predictions1 = base_model1_tf.predict(X_test_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model Accuracy using Count Vectorizer is 0.8283333333333334: Model accuracy using TFIDF is 0.675\n"
     ]
    }
   ],
   "source": [
    "cv_acc1 = accuracy_score(cv_predictions, y_test)\n",
    "tfidf_acc1 = accuracy_score(tfidf_predictions, y_test)\n",
    "print(\"Model Accuracy using Count Vectorizer is {}\".format(cv_acc1) + \\\n",
    "      \": \" +\"Model accuracy using TFIDF is {}\".format(tfidf_acc1) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              precision    recall  f1-score   support\n\n    Negative       0.83      0.67      0.74       350\n    Positive       0.63      0.81      0.71       250\n\n    accuracy                           0.73       600\n   macro avg       0.73      0.74      0.72       600\nweighted avg       0.75      0.72      0.73       600\n\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(cv_predictions1, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model1 = DecisionTreeClassifier()\n",
    "base_model1.fit(X_train_cv, y_train)\n",
    "cv_predictions1 = base_model1.predict(X_test_cv)\n",
    "base_model1_tf = DecisionTreeClassifier()\n",
    "base_model1_tf.fit(X_train_tf, y_train)\n",
    "tfidf_predictions1 = base_model1_tf.predict(X_test_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model Accuracy using Count Vectorizer is 0.8283333333333334: Model accuracy using TFIDF is 0.675\n"
     ]
    }
   ],
   "source": [
    "cv_acc1 = accuracy_score(cv_predictions, y_test)\n",
    "tfidf_acc1 = accuracy_score(tfidf_predictions, y_test)\n",
    "print(\"Model Accuracy using Count Vectorizer is {}\".format(cv_acc1) + \\\n",
    "      \": \" +\"Model accuracy using TFIDF is {}\".format(tfidf_acc1) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              precision    recall  f1-score   support\n\n    Negative       0.61      0.56      0.59       303\n    Positive       0.59      0.63      0.61       297\n\n    accuracy                           0.60       600\n   macro avg       0.60      0.60      0.60       600\nweighted avg       0.60      0.60      0.60       600\n\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(cv_predictions1, y_test))"
   ]
  }
 ]
}